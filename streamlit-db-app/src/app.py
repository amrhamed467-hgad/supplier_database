# app.py
import os
import re
import requests
import zipfile
from io import BytesIO
from pathlib import Path
from typing import Optional, Tuple, Dict, List
import urllib.parse  # <--- added

import pandas as pd
import streamlit as st
import base64  # <-- add this import

# ReportLab (PDF) + Arabic shaping
from reportlab.platypus import (
    SimpleDocTemplate,
    Table,
    TableStyle,
    Paragraph,
    Spacer,
    Image as RLImage,
    PageBreak,
)
from reportlab.lib import colors
from reportlab.lib.pagesizes import A4, landscape
from reportlab.lib.styles import ParagraphStyle
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont
import arabic_reshaper
from bidi.algorithm import get_display

try:
    from PIL import Image as PILImage
except Exception:
    PILImage = None

# === DB / filters (your existing modules) ===
from db.connection import (
    get_db_connection,
    fetch_data,
    fetch_financial_flow_view,
    fetch_contract_summary_view,
)
from components.filters import (
    create_company_dropdown,
    create_project_dropdown,
    create_type_dropdown,
    create_column_search,
)

# =========================================================
# Paths / Assets
# =========================================================
BASE_DIR = Path(__file__).resolve().parent
ASSETS_DIR = BASE_DIR / "assets"

LOGO_CANDIDATES = [ASSETS_DIR / "logo.png"]
WIDE_LOGO_CANDIDATES = [
    ASSETS_DIR / "logo_wide.png",
    ASSETS_DIR / "logo_wide.jpg",
    ASSETS_DIR / "logo_wide.jpeg",
    ASSETS_DIR / "logo_wide.webp",
]

AR_FONT_CANDIDATES = [
    ASSETS_DIR / "Cairo-Regular.ttf",
    ASSETS_DIR / "Amiri-Regular.ttf",
    Path("/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf"),
]

_AR_RE = re.compile(r"[\u0600-\u06FF]")  # Arabic unicode range


# =========================================================
# Small utils
# =========================================================
def _first_existing(paths) -> Optional[Path]:
    for p in paths:
        pth = Path(p)
        if pth.exists() and pth.is_file() and pth.stat().st_size > 0:
            return pth
    return None


def _image_size(path: Path) -> Tuple[int, int]:
    if PILImage:
        try:
            with PILImage.open(path) as im:
                return im.size  # (w, h)
        except Exception:
            pass
    return (600, 120)


def _site_logo_path() -> Optional[Path]:
    return _first_existing(LOGO_CANDIDATES)


def _wide_logo_path() -> Optional[Path]:
    return _first_existing(WIDE_LOGO_CANDIDATES)


def _first_existing_font_path() -> Optional[str]:
    p = _first_existing(AR_FONT_CANDIDATES)
    return str(p) if p else None


def register_arabic_font() -> Tuple[str, bool]:
    p = _first_existing_font_path()
    if p:
        name = os.path.splitext(os.path.basename(p))[0]
        try:
            pdfmetrics.registerFont(TTFont(name, p))
            return name, True
        except Exception:
            pass
    return "Helvetica", False


def looks_arabic(s: str) -> bool:
    return bool(_AR_RE.search(str(s or "")))


def shape_arabic(s: str) -> str:
    try:
        return get_display(arabic_reshaper.reshape(str(s)))
    except Exception:
        return str(s)


def _safe_filename(s: str) -> str:
    return (
        (s or "")
        .replace("/", "-").replace("\\", "-").replace(":", "-")
        .replace("*", "-").replace("?", "-").replace('"', "'")
        .replace("<", "(").replace(">", ")").replace("|", "-")
    )


# =========================================================
# Streamlit Config + Polished CSS
# =========================================================
st.set_page_config(
    page_title="Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ù…Ø§Ù„ÙŠØ© | HGAD",
    layout="wide",
    initial_sidebar_state="expanded",
)

st.markdown(
    """
<style>
:root{
  --bg:#0a0f1a; --panel:#0f172a; --panel-2:#0b1220; --muted:#9fb2d9;
  --text:#e5e7eb; --accent:#1E3A8A; --accent-2:#2563eb; --line:#23324d;
}

/* RTL base */
html, body{
  direction: rtl !important; text-align: right !important;
  font-family: "Cairo","Noto Kufi Arabic","Segoe UI",Tahoma,sans-serif !important;
  color:var(--text) !important; background:var(--bg) !important;
}

/* Sidebar always open + style */
[data-testid="stSidebar"]{
  transform:none !important; visibility:visible !important;
  width:340px !important; min-width:340px !important;
  background: linear-gradient(180deg, #0b1220, #0a1020);
  border-inline-start: 1px solid var(--line);
}
[data-testid="collapsedControl"],button[kind="header"],
button[title="Expand sidebar"],button[title="Collapse sidebar"],
[data-testid="stSidebarCollapseButton"]{ display:none !important; }

/* Fancy separator */
.hr-accent{ height:2px; border:0; background:linear-gradient(90deg, transparent, var(--accent), transparent); margin: 8px 0 14px; }

/* Cards */
.card{ background:var(--panel); border:1px solid var(--line); border-radius:16px; padding:14px; box-shadow:0 6px 24px rgba(3,10,30,.25); }
.card.soft{ background:var(--panel-2); }

/* Header banner */
.fin-head{
  display:flex; justify-content:space-between; align-items:center;
  border: 1px dashed rgba(37,99,235,.35); border-radius:16px;
  padding: 16px 18px; margin:8px 0 14px; background:linear-gradient(180deg,#0b1220,#0e1424);
}
.fin-head .line{ font-size:22px; font-weight:900; color:var(--text); }
.badge{ background:var(--accent); color:#fff; padding:6px 12px; border-radius:999px; font-weight:700; }

/* Date area */
.date-box{ border:1px solid var(--line); border-radius:16px; padding:12px; background:var(--panel-2); margin-bottom:12px; }
.date-row{ display:flex; gap:12px; flex-wrap:wrap; align-items:center; }
[data-testid="stDateInput"] input{
  background:#0f172a !important; color:var(--text) !important;
  border:1px solid var(--line) !important; border-radius:10px !important;
  text-align:center !important; height:44px !important; min-width:190px !important;
}
[data-testid="stDateInput"] label{ color:var(--muted) !important; font-weight:700; }

/* DataFrame look */
[data-testid="stDataFrame"] thead tr th{
  position: sticky; top: 0; z-index: 2;
  background: #132036; color: #e7eefc; font-weight:800; font-size:15px;
  border-bottom: 1px solid var(--line);
}
[data-testid="stDataFrame"] div[role="row"]{ font-size:14.5px; }
[data-testid="stDataFrame"] div[role="row"]:nth-child(even){ background: rgba(255,255,255,.03); }

/* Section title */
.hsec{ color:#e7eefc; font-weight:900; margin:6px 0 10px; font-size: 22px; }

/* Summary two-column panel */
.fin-panel{ display:grid; grid-template-columns: 1fr 1fr; gap:20px; margin-top:10px; }
.fin-table{ width:100%; border-collapse:collapse; table-layout:fixed; border-radius:14px; overflow:hidden; }
.fin-table th, .fin-table td{ border:1px solid var(--line); padding:12px; font-size:14.5px; white-space:normal; word-wrap:break-word; }
.fin-table tr:hover td{ background:#111a2d; transition: background .2s ease; }
.fin-table td.value{ background:#0f1a30; font-weight:800; text-align:center; width:34%; }
.fin-table td.label{ background:#0d1628; font-weight:700; text-align:right; width:66%; }

.hsec, .fin-head, h1, h3 {
  text-align: right !important;
  direction: rtl !important;
}
</style>
""",
    unsafe_allow_html=True,
)

# =========================================================
# Header (inline base64 small logo)
# =========================================================
def _logo_html() -> str:
    p = _site_logo_path()
    if not p:
        return ""
    ext = p.suffix.lower().lstrip(".") or "png"
    mime = f"image/{'jpeg' if ext in ('jpg','jpeg') else ext}"
    b64 = base64.b64encode(p.read_bytes()).decode("ascii")
    return f'<img src="data:{mime};base64,{b64}" width="64" />'

c_logo, c_title = st.columns([1, 6], gap="small")
with c_logo:
    st.markdown(_logo_html(), unsafe_allow_html=True)
with c_title:
    st.markdown(
        """
<h1 style="color:#e7eefc; font-weight:900; margin:0;">
  Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ù…Ø§Ù„ÙŠØ©
  <span style="font-size:18px; color:#9fb2d9; font-weight:600;">| HGAD Company</span>
</h1>
""",
        unsafe_allow_html=True,
    )
st.markdown('<hr class="hr-accent"/>', unsafe_allow_html=True)

# =========================================================
# Excel helpers (logo spans full width + tight spacing + Excel table)
# =========================================================
def _pick_excel_engine() -> Optional[str]:
    try:
        import xlsxwriter  # noqa: F401
        return "xlsxwriter"
    except Exception:
        pass
    try:
        import openpyxl  # noqa: F401
        return "openpyxl"
    except Exception:
        return None


def _estimate_col_widths_chars(df: pd.DataFrame) -> List[float]:
    """Estimate chars width per column (used for logo scaling & set_column)."""
    widths = []
    for col in df.columns:
        series = df[col]
        max_len = max([len(str(col))] + [len(str(v)) for v in series.values])
        widths.append(min(max_len + 4, 60))
    return widths


def _chars_to_pixels(chars: float) -> float:
    """Approx Excel mapping (â‰ˆ7.2 px per char)."""
    return chars * 7.2


def _compose_title(company: str, project: str, data_type: str, dfrom, dto) -> str:
    # RTL-friendly reversed arrow
    parts = []
    if company: parts.append(f"Ø§Ù„Ø´Ø±ÙƒØ©: {company}")
    if project: parts.append(f"Ø§Ù„Ù…Ø´Ø±ÙˆØ¹: {project}")
    if data_type: parts.append(f"Ø§Ù„Ù†ÙˆØ¹: {data_type}")
    if dfrom or dto:
        parts.append(f"Ø§Ù„ÙØªØ±Ø©: {dfrom or 'â€”'} â† {dto or 'â€”'}")
    return " | ".join(parts)


def _insert_wide_logo(ws, df: pd.DataFrame, start_row: int, start_col: int = 0) -> int:
    """
    Insert the wide logo scaled to span the full table width (firstâ†’last column).
    Return the next row index for the title. Only one tight title row after.
    """
    wlp = _wide_logo_path()
    if not wlp:
        return start_row

    widths_chars = _estimate_col_widths_chars(df)
    total_width_px = _chars_to_pixels(sum(widths_chars))

    try:
        img_w_px, img_h_px = _image_size(wlp)
        if img_w_px <= 0: img_w_px = 1000
        x_scale = max(0.1, total_width_px / float(img_w_px))
        y_scale = x_scale  # keep aspect ratio
        ws.insert_image(
            start_row, start_col, str(wlp),
            {"x_scale": x_scale, "y_scale": y_scale, "object_position": 2}
        )
        scaled_h_px = img_h_px * y_scale
        ws.set_row(start_row, int(scaled_h_px * 0.75))  # pxâ†’pt approx
        return start_row + 1
    except Exception:
        ws.set_row(start_row, 80)
        ws.insert_image(start_row, start_col, str(wlp), {"x_scale": 0.5, "y_scale": 0.5, "object_position": 2})
        return start_row + 1


def _write_excel_table(ws, workbook, df: pd.DataFrame, start_row: int, start_col: int) -> Tuple[int, int, int, int]:
    """Write df as formatted Excel Table with links labeled 'ÙØªØ­ Ø§Ù„Ø±Ø§Ø¨Ø·'."""
    hdr_fmt = workbook.add_format({"align": "right", "bold": True})
    fmt_text = workbook.add_format({"align": "right"})
    fmt_date = workbook.add_format({"align": "right", "num_format": "yyyy-mm-dd"})
    fmt_num  = workbook.add_format({"align": "right", "num_format": "#,##0.00"})
    fmt_link = workbook.add_format({"font_color": "blue", "underline": 1, "align": "right"})

    r0, c0 = start_row, start_col

    # headers
    for j, col in enumerate(df.columns):
        ws.write(r0, c0 + j, col, hdr_fmt)

    # body
    for i in range(len(df)):
        for j, col in enumerate(df.columns):
            val = df.iloc[i, j]
            colname = str(col)
            sval = "" if pd.isna(val) else str(val)
            if sval.startswith(("http://", "https://")) or ("Ø±Ø§Ø¨Ø·" in colname and sval):
                ws.write_url(r0 + 1 + i, c0 + j, sval, fmt_link, string="ÙØªØ­ Ø§Ù„Ø±Ø§Ø¨Ø·")
            else:
                if pd.api.types.is_datetime64_any_dtype(df[col]):
                    if pd.notna(val): ws.write_datetime(r0 + 1 + i, c0 + j, pd.to_datetime(val), fmt_date)
                    else: ws.write_blank(r0 + 1 + i, c0 + j, None, fmt_text)
                elif pd.api.types.is_numeric_dtype(df[col]):
                    if pd.notna(val): ws.write_number(r0 + 1 + i, c0 + j, float(val), fmt_num)
                    else: ws.write_blank(r0 + 1 + i, c0 + j, None, fmt_text)
                else:
                    ws.write(r0 + 1 + i, c0 + j, sval, fmt_text)

    r1 = r0 + len(df)
    c1 = c0 + len(df.columns) - 1

    ws.add_table(r0, c0, r1, c1, {
        "style": "Table Style Medium 9",
        "columns": [{"header": str(c)} for c in df.columns]
    })
    ws.freeze_panes(r0 + 1, c0)

    # column widths
    widths_chars = _estimate_col_widths_chars(df)
    for j, w in enumerate(widths_chars):
        ws.set_column(c0 + j, c0 + j, w)

    return r0, c0, r1, c1


def _auto_excel_sheet(writer, df: pd.DataFrame, sheet_name: str, title_line: str, put_logo: bool = True):
    engine = writer.engine
    safe_name = (sheet_name or "Sheet1")[:31]
    df_x = df.copy()

    if engine == "xlsxwriter":
        wb = writer.book
        ws = wb.add_worksheet(safe_name)
        writer.sheets[safe_name] = ws

        cur_row = 0
        if put_logo:
            # Logo full width, then title next row
            cur_row = _insert_wide_logo(ws, df_x, start_row=cur_row, start_col=0)

        # Title merged across all columns (right after logo)
        ncols = max(1, len(df_x.columns))
        title_fmt = wb.add_format({"bold": True, "align": "center", "valign": "vcenter", "font_size": 16})
        ws.merge_range(cur_row, 0, cur_row, ncols-1, title_line, title_fmt)
        ws.set_row(cur_row, 28)
        cur_row += 1

        # One blank row only
        ws.set_row(cur_row, 16)
        cur_row += 1

        # Table
        _write_excel_table(ws, wb, df_x, start_row=cur_row, start_col=0)
        ws.set_zoom(115)
        ws.set_margins(left=0.3, right=0.3, top=0.5, bottom=0.5)
    else:
        df_x.to_excel(writer, index=False, sheet_name=safe_name)


def make_excel_bytes(df: pd.DataFrame, sheet_name: str, title_line: str, put_logo: bool = True) -> Optional[bytes]:
    engine = _pick_excel_engine()
    if engine is None:
        return None
    buf = BytesIO()
    with pd.ExcelWriter(buf, engine=engine) as writer:
        _auto_excel_sheet(writer, df, sheet_name, title_line, put_logo=put_logo)
    buf.seek(0)
    return buf.getvalue()


def make_excel_combined_two_sheets(dfs: Dict[str, pd.DataFrame], titles: Dict[str, str], put_logo: bool = True) -> Optional[bytes]:
    engine = _pick_excel_engine()
    if engine is None:
        return None
    buf = BytesIO()
    with pd.ExcelWriter(buf, engine=engine) as writer:
        for sheet, df in dfs.items():
            _auto_excel_sheet(writer, df, sheet, titles.get(sheet, sheet), put_logo=put_logo)
    buf.seek(0)
    return buf.getvalue()


def make_excel_single_sheet_stacked(dfs: Dict[str, pd.DataFrame], title_line: str, sheet_name="ØªÙ‚Ø±ÙŠØ±_Ù…ÙˆØ­Ø¯", put_logo: bool = True) -> Optional[bytes]:
    engine = _pick_excel_engine()
    if engine is None:
        return None
    buf = BytesIO()
    with pd.ExcelWriter(buf, engine=engine) as writer:
        if writer.engine == "xlsxwriter":
            wb = writer.book
            ws = wb.add_worksheet(sheet_name[:31])
            writer.sheets[sheet_name[:31]] = ws

            cur_row = 0
            if put_logo:
                widest_df = max(dfs.values(), key=lambda d: len(d.columns))
                cur_row = _insert_wide_logo(ws, widest_df, start_row=cur_row, start_col=0)

            max_cols = max((len(df.columns) for df in dfs.values()), default=1)
            big_title_fmt = wb.add_format({"bold": True, "align": "center", "valign": "vcenter", "font_size": 16})
            ws.merge_range(cur_row, 0, cur_row, max_cols-1, title_line, big_title_fmt)
            ws.set_row(cur_row, 28)
            cur_row += 2  # one blank row

            for section_title, df in dfs.items():
                title_fmt = wb.add_format({"bold": True, "align": "right", "font_size": 12})
                ws.merge_range(cur_row, 0, cur_row, len(df.columns)-1, section_title, title_fmt)
                cur_row += 2
                _write_excel_table(ws, wb, df, start_row=cur_row, start_col=0)
                cur_row += len(df) + 3
            ws.set_zoom(115)
        else:
            out = []
            for sec, df in dfs.items():
                title_row = pd.DataFrame([[sec] + [""] * (len(df.columns) - 1)], columns=df.columns)
                out += [title_row, df, pd.DataFrame([[""] * len(df.columns)], columns=df.columns)]
            big = pd.concat(out, ignore_index=True)
            big.to_excel(writer, index=False, sheet_name=sheet_name[:31])
    buf.seek(0)
    return buf.getvalue()


def make_csv_utf8(df: pd.DataFrame) -> bytes:
    return df.to_csv(index=False, encoding="utf-8-sig").encode("utf-8-sig")


# --- ADD / MOVE: Drive helpers (place before main) ---
def _drive_share_to_direct_download(share_url: str) -> str | None:
    """Ø­ÙˆÙ‘Ù„ Ø±Ø§Ø¨Ø· Ù…Ø´Ø§Ø±ÙƒØ© Drive Ø¥Ù„Ù‰ Ø±Ø§Ø¨Ø· ØªÙ†Ø²ÙŠÙ„ Ù…Ø¨Ø§Ø´Ø± (uc?export=download&id=...)."""
    if not share_url:
        return None
    m = re.search(r'/d/([a-zA-Z0-9_-]{10,})', share_url)
    if m:
        fid = m.group(1)
        return f"https://drive.google.com/uc?export=download&id={fid}"
    m2 = re.search(r'[?&]id=([a-zA-Z0-9_-]{10,})', share_url)
    if m2:
        return f"https://drive.google.com/uc?export=download&id={m2.group(1)}"
    return share_url

def _create_zip_from_links(df: pd.DataFrame, link_col: str) -> Tuple[Optional[bytes], List[Tuple[int,str]]]:
    """
    Download all files from df[link_col] (converting Drive share links to direct)
    and return (zip_bytes, errors).
    """
    if df is None or df.empty or link_col not in df.columns:
        return None, [(-1, "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø±ÙˆØ§Ø¨Ø·")]
    buf = BytesIO()
    errors = []
    with zipfile.ZipFile(buf, mode="w", compression=zipfile.ZIP_DEFLATED) as zf:
        for idx, row in df.iterrows():
            share_url = str(row.get(link_col, "") or "")
            direct = _drive_share_to_direct_download(share_url)
            if not direct:
                errors.append((idx, "Ø±Ø§Ø¨Ø· ØºÙŠØ± ØµØ§Ù„Ø­"))
                continue
            try:
                resp = requests.get(direct, stream=True, timeout=30)
                resp.raise_for_status()

                # Try to obtain a proper filename and decode percent-encoding / latin1 -> utf-8 if needed
                fname = None
                cd = resp.headers.get("content-disposition", "") or ""

                # RFC 5987 encoded filename*: filename*=UTF-8''%D8%A7%D8%B3%D9%85.pdf
                m = re.search(r"filename\*=([^']*)''(.+)", cd)
                if m:
                    enc = m.group(1).strip().upper() or "UTF-8"
                    raw = m.group(2)
                    try:
                        fname = urllib.parse.unquote(raw)
                    except Exception:
                        fname = raw

                # Fallback to simple filename="..." or filename=...
                if not fname:
                    m2 = re.search(r'filename="?([^";]+)"?', cd)
                    if m2:
                        raw2 = m2.group(1)
                        # try to decode latin1 -> utf-8 (common issue with headers carrying utf-8 bytes)
                        try:
                            fname = raw2.encode("latin-1").decode("utf-8")
                        except Exception:
                            try:
                                fname = urllib.parse.unquote(raw2)
                            except Exception:
                                fname = raw2

                # If still no filename, derive from URL or index
                if not fname:
                    # try derive from end of URL (after last slash)
                    tail = direct.split("/")[-1]
                    tail = tail.split("?")[0] or ""
                    if tail:
                        try:
                            fname = urllib.parse.unquote(tail)
                        except Exception:
                            fname = tail
                    else:
                        fid = re.search(r'/d/([a-zA-Z0-9_-]{10,})', share_url)
                        fname = f"file_{idx}_{fid.group(1) if fid else idx}"

                # ensure fname is a str and sanitized minimally
                if not isinstance(fname, str):
                    fname = str(fname)

                zf.writestr(fname, resp.content)
            except Exception as e:
                errors.append((idx, str(e)))
    buf.seek(0)
    if buf.getbuffer().nbytes == 0:
        return None, errors
    return buf.getvalue(), errors

# =========================================================
# PDF helpers (clean + zebra + anchors + dynamic title)
# ******* FINAL FIX FOR 'Ø±Ù‚Ù… Ø§Ù„Ø´ÙŠÙƒ' (no commas) **********
# =========================================================
def _normalize_name(s: str) -> str:
    """Normalize Arabic column names: remove spaces, tatweel and zero-width marks."""
    return re.sub(r'[\s\u0640\u200c\u200d\u200e\u200f]+', '', str(s or ''))

def _plain_number_no_commas(x) -> str:
    """Render number as plain string without thousands separators; trim trailing .00."""
    if pd.isna(x):
        return ""
    sx = str(x).replace(",", "").strip()
    try:
        f = float(sx)
        if float(int(f)) == f:
            return str(int(f))
        s = f"{f}"
        if "." in s:
            s = s.rstrip("0").rstrip(".")
        return s
    except Exception:
        return str(x)

def _format_numbers_for_display(df: pd.DataFrame, no_comma_cols: Optional[List[str]] = None) -> pd.DataFrame:
    """
    Format numbers for PDF display.
    * Any column explicitly listed in no_comma_cols
    * OR any column whose normalized name contains 'Ø´ÙŠÙƒ'
      is rendered as plain text (no thousands separators).
    """
    out = df.copy()
    requested = {_normalize_name(c) for c in (no_comma_cols or [])}

    for c in out.columns:
        c_norm = _normalize_name(c)
        force_plain = (c_norm in requested) or ("Ø´ÙŠÙƒ" in c_norm)

        if force_plain:
            out[c] = out[c].map(_plain_number_no_commas)
            continue

        if pd.api.types.is_numeric_dtype(out[c]):
            out[c] = out[c].map(lambda x: "" if pd.isna(x) else f"{float(x):,.2f}")
        else:
            def _fmt_cell(v):
                s = str(v)
                try:
                    if s.strip().endswith("%"):
                        return s
                    fv = float(s.replace(",", ""))
                    return f"{fv:,.2f}"
                except Exception:
                    return s
            out[c] = out[c].map(_fmt_cell)
    return out


def compose_pdf_title(company: str, project: str, data_type: str, dfrom, dto) -> str:
    return _compose_title(company, project, data_type, dfrom, dto)


def _pdf_header_elements(title_line: str) -> Tuple[List, float]:
    font_name, arabic_ok = register_arabic_font()
    page = landscape(A4)
    left, right, top, bottom = 14, 14, 18, 14
    avail_w = page[0] - left - right

    title_style = ParagraphStyle(
        name="Title", fontName=font_name, fontSize=14, leading=17,
        alignment=1, textColor=colors.HexColor("#1b1b1b")
    )

    if arabic_ok:
        title_line = shape_arabic(title_line)

    elements = []
    wlp = _wide_logo_path()
    if wlp and wlp.exists():
        try:
            if PILImage:
                w_px, h_px = _image_size(wlp)
                ratio = h_px / float(w_px) if w_px else 0.2
                img_h = max(22, avail_w * ratio * 0.55)
            else:
                img_h = 36
            logo_img = RLImage(str(wlp), hAlign="CENTER")
            logo_img.drawWidth = avail_w
            logo_img.drawHeight = img_h
            elements.append(logo_img)
            elements.append(Spacer(1, 8))
        except Exception:
            pass

    elements.append(Paragraph(title_line, title_style))
    elements.append(Spacer(1, 8))
    return elements, avail_w


def _pdf_table(df: pd.DataFrame, title: str = "", max_col_width: int = 120, font_size: float = 8.0, avail_width: Optional[float] = None) -> list:
    font_name, _ = register_arabic_font()
    hdr_style = ParagraphStyle(name="Hdr", fontName=font_name, fontSize=font_size+0.6, textColor=colors.whitesmoke, alignment=1, leading=font_size+1.8)
    cell_rtl  = ParagraphStyle(name="CellR", fontName=font_name, fontSize=font_size, leading=font_size+1.5, alignment=2, textColor=colors.black)
    cell_ltr  = ParagraphStyle(name="CellL", fontName=font_name, fontSize=font_size, leading=font_size+1.5, alignment=0, textColor=colors.black)
    link_style = ParagraphStyle(name="Link", fontName=font_name, fontSize=font_size, alignment=2, textColor=colors.HexColor("#1a56db"), underline=True)

    blocks = []
    if title:
        tstyle = ParagraphStyle(name="Sec", fontName=font_name, fontSize=font_size+2, alignment=2, textColor=colors.HexColor("#1E3A8A"))
        blocks += [Paragraph(shape_arabic(title), tstyle), Spacer(1, 4)]

    headers = [Paragraph(shape_arabic(c) if looks_arabic(c) else str(c), hdr_style) for c in df.columns]
    rows = [headers]
    for _, r in df.iterrows():
        cells = []
        for c in df.columns:
            sval = "" if pd.isna(r[c]) else str(r[c])
            if sval.startswith(("http://", "https://")) or ("Ø±Ø§Ø¨Ø·" in str(c) and sval):
                html = f'<link href="{sval}">{shape_arabic("ÙØªØ­ Ø§Ù„Ø±Ø§Ø¨Ø·")}</link>'
                cells.append(Paragraph(html, link_style))
            else:
                is_ar = looks_arabic(sval)
                cells.append(Paragraph(shape_arabic(sval) if is_ar else sval, cell_rtl if is_ar else cell_ltr))
        rows.append(cells)

    col_widths = []
    for c in df.columns:
        max_len = max(len(str(c)), df[c].astype(str).map(len).max())
        col_widths.append(min(max_len * 6.4, max_col_width))
    if avail_width:
        total = sum(col_widths)
        if total > avail_width:
            factor = avail_width / total
            col_widths = [w * factor for w in col_widths]

    table = Table(rows, repeatRows=1, colWidths=col_widths)
    table.setStyle(TableStyle([
        ("FONTNAME", (0,0), (-1,-1), font_name),
        ("FONTSIZE", (0,0), (-1,-1), font_size),
        ("BACKGROUND", (0,0), (-1,0), colors.HexColor("#1E3A8A")),
        ("TEXTCOLOR", (0,0), (-1,0), colors.whitesmoke),
        ("VALIGN", (0,0), (-1,-1), "MIDDLE"),
        ("LEFTPADDING", (0,0), (-1,-1), 3),
        ("RIGHTPADDING", (0,0), (-1,-1), 3),
        ("TOPPADDING", (0,0), (-1,-1), 2),
        ("BOTTOMPADDING", (0,0), (-1,-1), 2),
        ("GRID", (0,0), (-1,-1), 0.35, colors.HexColor("#cbd5e1")),
        ("ROWBACKGROUNDS", (0,1), (-1,-1), [colors.white, colors.HexColor("#f7fafc")]),
    ]))
    blocks.append(table)
    return blocks


def _choose_pdf_font(df: pd.DataFrame) -> Tuple[int, float]:
    n = len(df.columns)
    if n >= 12: return 110, 7.0
    if n >= 9:  return 125, 7.5
    return 150, 8.0


def make_pdf_bytes(df: pd.DataFrame, title_line: str) -> bytes:
    page = landscape(A4)
    left, right, top, bottom = 14, 14, 18, 14
    buf = BytesIO()
    doc = SimpleDocTemplate(buf, pagesize=page, rightMargin=right, leftMargin=left, topMargin=top, bottomMargin=bottom)

    elements, avail_w = _pdf_header_elements(title_line)
    max_col_width, base_font = _choose_pdf_font(df)
    elements += _pdf_table(df, max_col_width=max_col_width, font_size=base_font, avail_width=avail_w)
    doc.build(elements)
    buf.seek(0)
    return buf.getvalue()


def make_pdf_combined(summary_df: pd.DataFrame, flow_df: pd.DataFrame, title_line: str) -> bytes:
    page = landscape(A4)
    left, right, top, bottom = 14, 14, 18, 14
    buf = BytesIO()
    doc = SimpleDocTemplate(buf, pagesize=page, rightMargin=right, leftMargin=left, topMargin=top, bottomMargin=bottom)

    header_elements, avail_w = _pdf_header_elements(title_line)
    elements = list(header_elements)

    max_w_s, f_s = _choose_pdf_font(summary_df)
    elements += _pdf_table(summary_df, title="Ù…Ù„Ø®Øµ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹", max_col_width=max_w_s, font_size=f_s, avail_width=avail_w)
    elements.append(PageBreak())
    max_w_f, f_f = _choose_pdf_font(flow_df)
    elements += _pdf_table(flow_df, title="Ø¯ÙØªØ± Ø§Ù„ØªØ¯ÙÙ‚", max_col_width=max_w_f, font_size=f_f, avail_width=avail_w)

    doc.build(elements)
    buf.seek(0)
    return buf.getvalue()


# =========================================================
# Summary render helpers
# =========================================================
def fin_panel_two_tables(left_items: List[Tuple[str, str]], right_items: List[Tuple[str, str]]):
    def _table_html(items):
        rows = []
        for label, value in items:
            rows.append(f'<tr><td class="value">{value}</td><td class="label">{label}</td></tr>')
        return f'<table class="fin-table">{"".join(rows)}</table>'
    html = f'<div class="fin-panel card"><div class="soft">{_table_html(right_items)}</div><div class="soft">{_table_html(left_items)}</div></div>'
    st.markdown(html, unsafe_allow_html=True)


def _apply_date_filter(df: pd.DataFrame, dfrom, dto) -> pd.DataFrame:
    if df is None or df.empty or (not dfrom and not dto): return df
    date_cols = [c for c in df.columns if any(k in str(c) for k in ["ØªØ§Ø±ÙŠØ®", "Ø¥ØµØ¯Ø§Ø±", "date", "ØªØ¹Ø§Ù‚Ø¯"])]
    if not date_cols: return df
    out = df.copy()
    for col in date_cols:
        try:
            dseries = pd.to_datetime(out[col], errors="coerce").dt.date
            if dfrom: out = out[dseries >= dfrom]
            if dto:   out = out[dseries <= dto]
        except Exception:
            pass
    return out


def _fmt_value(v) -> str:
    try:
        if isinstance(v, str) and v.strip().endswith("%"): return v
        f = float(str(v).replace(",", "")); return f"{f:,.2f}"
    except Exception:
        return "" if (v is None or (isinstance(v, float) and pd.isna(v))) else str(v)


def _row_to_pairs_from_data(row: pd.Series) -> List[Tuple[str, str]]:
    ignore_substrings = {"id", "ID", "companyid", "contractid"}
    pairs = []
    for col, val in row.items():
        if any(k in str(col).lower() for k in ignore_substrings): continue
        sval = _fmt_value(val)
        if sval == "" or sval.lower() == "nan": continue
        pairs.append((str(col), sval))
    return pairs


def _split_pairs_two_columns(pairs: List[Tuple[str, str]]) -> Tuple[List[Tuple[str, str]], List[Tuple[str, str]]]:
    n = len(pairs); mid = (n + 1)//2
    right = pairs[:mid]; left = pairs[mid:]
    return left, right


# =========================================================
# Main App
# =========================================================
def main() -> None:
    conn = get_db_connection()
    if conn is None:
        st.error("ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª. ÙŠØ±Ø¬Ù‰ Ù…Ø±Ø§Ø¬Ø¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§ØªØµØ§Ù„ ÙˆØ§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ØªØ´ØºÙŠÙ„ Ø§Ù„Ø®Ø§Ø¯Ù….")
        return

    with st.sidebar:
        # Drive link (left-most beautiful anchor with icon + title)
        DRIVE_FILE_URL = "https://drive.google.com/file/d/1BBjG_OWNr__BpDN6MOsj_VG8M0D8_b78/view?usp=drive_link"
        st.markdown(
            f'''
            <div style="padding:8px 6px 12px 6px; display:flex; align-items:center; justify-content:flex-start;">
              <a href="{DRIVE_FILE_URL}" target="_blank" rel="noopener noreferrer"
                 title="Ø§Ù„ØªØ¯ÙÙ‚ Ù†Ù‚Ø¯ÙŠ Ø§Ù„Ø§Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ÙŠ  31-10-2025"
                 style="display:inline-flex; gap:10px; align-items:center; text-decoration:none; padding:6px 10px; border-radius:10px; background:linear-gradient(90deg, rgba(37,99,235,0.10), rgba(37,99,235,0.04)); border:1px solid rgba(37,99,235,0.10);">
                <span style="font-size:20px; line-height:1.0;">ğŸ“</span>
                <span style="font-weight:800; color:#dbeafe; font-size:13px;">Ø§Ù„ØªØ¯ÙÙ‚ Ù†Ù‚Ø¯ÙŠ Ø§Ù„Ø§Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ÙŠ  31-10-2025</span>
              </a>
            </div>
            ''',
            unsafe_allow_html=True,
        )

        st.title("Ø¹ÙˆØ§Ù…Ù„ Ø§Ù„ØªØµÙÙŠØ©")
        company_name = create_company_dropdown(conn)
        project_name = create_project_dropdown(conn, company_name)
        type_label, type_key = create_type_dropdown()

    if not company_name or not project_name or not type_key:
        st.info("Ø¨Ø±Ø¬Ø§Ø¡ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø´Ø±ÙƒØ© ÙˆØ§Ù„Ù…Ø´Ø±ÙˆØ¹ ÙˆÙ†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ Ù„Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬.")
        return

    # Global date filters (main area)
    g_date_from, g_date_to = None, None
    with st.container():
        st.markdown('<div class="date-box"><div class="date-row">', unsafe_allow_html=True)
        c1, c2 = st.columns([1, 1], gap="small")
        with c1: g_date_from = st.date_input("Ù…Ù† ØªØ§Ø±ÙŠØ®", value=None, key="g_from", format="YYYY-MM-DD")
        with c2: g_date_to   = st.date_input("Ø¥Ù„Ù‰ ØªØ§Ø±ÙŠØ®", value=None, key="g_to", format="YYYY-MM-DD")
        st.markdown('</div></div>', unsafe_allow_html=True)

    # =======================
    # Financial Report Mode
    # =======================
    if type_key == "financial_report":
        df_summary = fetch_contract_summary_view(conn, company_name, project_name)
        if df_summary.empty:
            st.warning("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„Ø®Øµ Ø§Ù„Ø¹Ù‚Ø¯ Ù„Ù‡Ø°Ø§ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹.")
            return
        row = df_summary.iloc[0]

        header_company = company_name or "â€”"
        header_project = project_name or "â€”"
        header_date = str(row.get("ØªØ§Ø±ÙŠØ® Ø§Ù„ØªØ¹Ø§Ù‚Ø¯", "â€”"))
        st.markdown(
            f"""
            <div class="fin-head">
                <div class="line">
                    <strong>Ø§Ù„Ø´Ø±ÙƒØ©:</strong> {header_company}
                    &nbsp;&nbsp;|&nbsp;&nbsp;
                    <strong>Ø§Ù„Ù…Ø´Ø±ÙˆØ¹:</strong> {header_project}
                    &nbsp;&nbsp;|&nbsp;&nbsp;
                    <strong>ØªØ§Ø±ÙŠØ® Ø§Ù„ØªØ¹Ø§Ù‚Ø¯:</strong> {header_date}
                </div>
                <span class="badge">ØªÙ‚Ø±ÙŠØ± Ù…Ø§Ù„ÙŠ</span>
            </div>
            """,
            unsafe_allow_html=True,
        )

        # Summary panel from data only (name right, value left)
        summary_pairs = _row_to_pairs_from_data(row)
        if summary_pairs:
            left_items, right_items = _split_pairs_two_columns(summary_pairs)
            st.markdown('<h3 class="hsec">Ù…Ù„Ø®Øµ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹</h3>', unsafe_allow_html=True)
            fin_panel_two_tables(left_items=left_items, right_items=right_items)

        # Titles for exports (RTL arrow)
        title_summary = compose_pdf_title(company_name, project_name, "Ù…Ù„Ø®Øµ", g_date_from, g_date_to)
        title_flow    = compose_pdf_title(company_name, project_name, "Ø¯ÙØªØ± Ø§Ù„ØªØ¯ÙÙ‚", g_date_from, g_date_to)
        title_all     = compose_pdf_title(company_name, project_name, "Ù…Ù„Ø®Øµ + Ø¯ÙØªØ± Ø§Ù„ØªØ¯ÙÙ‚", g_date_from, g_date_to)

        # ---- Downloads (summary) ----
        xlsx_sum = make_excel_bytes(df_summary, sheet_name="Ù…Ù„Ø®Øµ", title_line=title_summary, put_logo=True)
        if xlsx_sum:
            st.download_button("ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ù…Ù„Ø®Øµ ÙƒÙ€ Excel", xlsx_sum,
                               file_name=_safe_filename(f"Ù…Ù„Ø®Øµ_{company_name}_{project_name}.xlsx"),
                               mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
        pdf_sum = make_pdf_bytes(_format_numbers_for_display(df_summary), title_line=title_summary)
        st.download_button("ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ù…Ù„Ø®Øµ ÙƒÙ€ PDF", pdf_sum,
                           file_name=_safe_filename(f"Ù…Ù„Ø®Øµ_{company_name}_{project_name}.pdf"),
                           mime="application/pdf")

        st.markdown('<hr class="hr-accent"/>', unsafe_allow_html=True)

        # ---- Ledger (v_financial_flow) ----
        st.markdown('<h3 class="hsec">Ø¯ÙØªØ± Ø§Ù„ØªØ¯ÙÙ‚ (v_financial_flow)</h3>', unsafe_allow_html=True)
        df_flow = fetch_financial_flow_view(conn, company_name, project_name, g_date_from, g_date_to)
        if df_flow.empty:
            st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø­Ø±ÙƒØ§Øª Ù…Ø·Ø§Ø¨Ù‚Ø© Ø¶Ù…Ù† Ø§Ù„Ù†Ø·Ø§Ù‚ Ø§Ù„Ù…Ø­Ø¯Ø¯.")
            return

        col_search, term = create_column_search(df_flow)
        if col_search and term:
            df_flow = df_flow[df_flow[col_search].astype(str).str.contains(str(term), case=False, na=False)]
            if df_flow.empty:
                st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†ØªØ§Ø¦Ø¬ Ø¨Ø¹Ø¯ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¨Ø­Ø«.")
                return

        df_flow_display = df_flow.drop(columns=["companyid", "contractid"], errors="ignore")
        st.markdown('<div class="card soft">', unsafe_allow_html=True)
        st.dataframe(df_flow_display, use_container_width=True, hide_index=True)
        st.markdown('</div>', unsafe_allow_html=True)

        # Individual downloads
        xlsx_flow = make_excel_bytes(df_flow_display, sheet_name="Ø¯ÙØªØ±_Ø§Ù„ØªØ¯ÙÙ‚", title_line=title_flow, put_logo=True)
        if xlsx_flow:
            st.download_button("ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ø¯ÙØªØ± ÙƒÙ€ Excel", xlsx_flow,
                               file_name=_safe_filename(f"Ø¯ÙØªØ±_Ø§Ù„ØªØ¯ÙÙ‚_{company_name}_{project_name}.xlsx"),
                               mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
        csv_flow = make_csv_utf8(df_flow_display)
        st.download_button("ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ø¯ÙØªØ± ÙƒÙ€ CSV", csv_flow,
                           file_name=_safe_filename(f"Ø¯ÙØªØ±_Ø§Ù„ØªØ¯ÙÙ‚_{company_name}_{project_name}.csv"),
                           mime="text/csv")

        # PDF: keep Ø±Ù‚Ù… Ø§Ù„Ø´ÙŠÙƒ without commas (and any column containing 'Ø´ÙŠÙƒ')
        pdf_flow_df = _format_numbers_for_display(df_flow_display, no_comma_cols=["Ø±Ù‚Ù… Ø§Ù„Ø´ÙŠÙƒ"])
        pdf_flow = make_pdf_bytes(pdf_flow_df, title_line=title_flow)
        st.download_button("ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ø¯ÙØªØ± ÙƒÙ€ PDF", pdf_flow,
                           file_name=_safe_filename(f"Ø¯ÙØªØ±_Ø§Ù„ØªØ¯ÙÙ‚_{company_name}_{project_name}.pdf"),
                           mime="application/pdf")

        # New: Download all linked files (ZIP) for the displayed ledger if a link column exists
        link_cols = [c for c in df_flow_display.columns if "Ø±Ø§Ø¨Ø·" in str(c)]
        if link_cols:
            link_col = link_cols[0]
            btn_label = "â¬‡ï¸ ØªÙ†Ø²ÙŠÙ„ Ø§Ù„ÙƒÙ„ (ZIP)"
            if type_label and "Ù…Ø³ØªØ®Ù„Øµ" in str(type_label):
                btn_label = "â¬‡ï¸ ØªÙ†Ø²ÙŠÙ„ ÙƒÙ„ Ø§Ù„Ù…Ø³ØªØ®Ù„ØµØ§Øª (ZIP)"

            # Create the ZIP then show a single download button (spinner while creating)
            with st.spinner("Ø¬Ø§Ø±Ù Ø¥Ù†Ø´Ø§Ø¡ Ø£Ø±Ø´ÙŠÙ ZIP ..."):
                zip_bytes, errors = _create_zip_from_links(df_flow_display, link_col)

            if not zip_bytes:
                st.error("ÙØ´Ù„ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù ZIP. ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø£Ùˆ Ø§Ù„Ø§ØªØµØ§Ù„.")
                if errors:
                    st.warning(f"Ø£Ø®Ø·Ø§Ø¡: {len(errors)} Ø­Ø§Ù„Ø§Øª.")
            else:
                st.download_button(label=btn_label,
                                   data=zip_bytes,
                                   file_name=_safe_filename(f"{type_label or 'Ø§Ù„Ù…Ù„ÙØ§Øª'}_{company_name}_{project_name}.zip"),
                                   mime="application/zip")
                if errors:
                    st.warning(f"Ø¨Ø¹Ø¶ Ø§Ù„Ù…Ù„ÙØ§Øª Ù„Ù… ØªÙØ­Ù…Ù‘Ù„ ({len(errors)}).")

        # Combined
        st.markdown("### ØªÙ†Ø²ÙŠÙ„ ØªÙ‚Ø±ÙŠØ± Ù…ÙˆØ­Ù‘Ø¯")
        excel_two = make_excel_combined_two_sheets(
            {"Ù…Ù„Ø®Øµ": df_summary, "Ø¯ÙØªØ±_Ø§Ù„ØªØ¯ÙÙ‚": df_flow_display},
            titles={"Ù…Ù„Ø®Øµ": title_summary, "Ø¯ÙØªØ±_Ø§Ù„ØªØ¯ÙÙ‚": title_flow},
            put_logo=True
        )
        if excel_two:
            st.download_button("Excel Ù…ÙˆØ­Ù‘Ø¯ (ÙˆØ±Ù‚ØªØ§Ù†)", excel_two,
                               file_name=_safe_filename(f"ØªÙ‚Ø±ÙŠØ±_Ù…Ø§Ù„ÙŠ_{company_name}_{project_name}_ÙˆØ±Ù‚ØªÙŠÙ†.xlsx"),
                               mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

        excel_one = make_excel_single_sheet_stacked(
            {"Ù…Ù„Ø®Øµ": df_summary, "Ø¯ÙØªØ±_Ø§Ù„ØªØ¯ÙÙ‚": df_flow_display},
            title_line=title_all, sheet_name="ØªÙ‚Ø±ÙŠØ±_Ù…ÙˆØ­Ø¯", put_logo=True
        )
        if excel_one:
            st.download_button("Excel Ù…ÙˆØ­Ù‘Ø¯ (ÙˆØ±Ù‚Ø© ÙˆØ§Ø­Ø¯Ø©)", excel_one,
                               file_name=_safe_filename(f"ØªÙ‚Ø±ÙŠØ±_Ù…Ø§Ù„ÙŠ_{company_name}_{project_name}_ÙˆØ±Ù‚Ø©_ÙˆØ§Ø­Ø¯Ø©.xlsx"),
                               mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

        pdf_all = make_pdf_combined(
            _format_numbers_for_display(df_summary),
            _format_numbers_for_display(df_flow_display, no_comma_cols=["Ø±Ù‚Ù… Ø§Ù„Ø´ÙŠÙƒ"]),
            title_line=title_all
        )
        st.download_button("PDF Ù…ÙˆØ­Ù‘Ø¯ (Ù…Ù„Ø®Øµ + Ø¯ÙØªØ±)", pdf_all,
                           file_name=_safe_filename(f"ØªÙ‚Ø±ÙŠØ±_Ù…Ø§Ù„ÙŠ_{company_name}_{project_name}.pdf"),
                           mime="application/pdf")
        return

    # =======================
    # Other data types (classic table modes)
    # =======================
    df = fetch_data(conn, company_name, project_name, type_key)
    if df.empty:
        st.warning("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø·Ø§Ø¨Ù‚Ø© Ù„Ù„Ø§Ø®ØªÙŠØ§Ø±Ø§Øª Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©.")
        return

    df = _apply_date_filter(df, g_date_from, g_date_to)

    search_column, search_term = create_column_search(df)
    if search_column and search_term:
        df = df[df[search_column].astype(str).str.contains(str(search_term), case=False, na=False)]
        if df.empty:
            st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†ØªØ§Ø¦Ø¬ Ø¨Ø¹Ø¯ ØªØ·Ø¨ÙŠÙ‚ Ù…Ø¹ÙŠØ§Ø± Ø§Ù„Ø¨Ø­Ø«.")
            return

    column_config = {}
    for col in df.columns:
        if "Ø±Ø§Ø¨Ø·" in str(col):
            column_config[col] = st.column_config.LinkColumn(label=col, display_text="ÙØªØ­ Ø§Ù„Ø±Ø§Ø¨Ø·")

    st.markdown('<h3 class="hsec">Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª</h3>', unsafe_allow_html=True)
    st.markdown('<div class="card soft">', unsafe_allow_html=True)
    st.dataframe(df, column_config=column_config, use_container_width=True, hide_index=True)
    st.markdown('</div>', unsafe_allow_html=True)

    title_generic = compose_pdf_title(company_name, project_name, type_label, g_date_from, g_date_to)

    xlsx_bytes = make_excel_bytes(df, sheet_name="Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", title_line=title_generic, put_logo=True)
    if xlsx_bytes:
        st.download_button("ØªÙ†Ø²ÙŠÙ„ ÙƒÙ€ Excel (XLSX)", xlsx_bytes,
                           file_name=_safe_filename(f"{type_key}_{company_name}_{project_name}.xlsx"),
                           mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

    csv_bytes = make_csv_utf8(df)
    st.download_button("ØªÙ†Ø²ÙŠÙ„ ÙƒÙ€ CSV (UTF-8)", csv_bytes,
                       file_name=_safe_filename(f"{type_key}_{company_name}_{project_name}.csv"),
                       mime="text/csv")

    pdf_bytes = make_pdf_bytes(_format_numbers_for_display(df), title_line=title_generic)
    st.download_button("ØªÙ†Ø²ÙŠÙ„ ÙƒÙ€ PDF", pdf_bytes,
                       file_name=_safe_filename(f"{type_key}_{company_name}_{project_name}.pdf"),
                       mime="application/pdf")

    # New: Download all linked files for generic data types (appears after PDF button)
    link_cols = [c for c in df.columns if "Ø±Ø§Ø¨Ø·" in str(c)]
    if link_cols:
        link_col = link_cols[0]
        btn_label = "â¬‡ï¸ ØªÙ†Ø²ÙŠÙ„ Ø§Ù„ÙƒÙ„ (ZIP)"
        if type_label and "Ù…Ø³ØªØ®Ù„Øµ" in str(type_label):
            btn_label = "â¬‡ï¸ ØªÙ†Ø²ÙŠÙ„ ÙƒÙ„ Ø§Ù„Ù…Ø³ØªØ®Ù„ØµØ§Øª (ZIP)"

        # Create the ZIP then show a single download button (spinner while creating)
        with st.spinner("Ø¬Ø§Ø±Ù Ø¥Ù†Ø´Ø§Ø¡ Ø£Ø±Ø´ÙŠÙ ZIP ..."):
            zip_bytes, errors = _create_zip_from_links(df, link_col)

        if not zip_bytes:
            st.error("ÙØ´Ù„ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù ZIP. ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø£Ùˆ Ø§Ù„Ø§ØªØµØ§Ù„.")
        else:
            st.download_button(label="ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù ZIP", data=zip_bytes,
                               file_name=_safe_filename(f"{type_label or 'Ø§Ù„Ù…Ù„ÙØ§Øª'}_{company_name}_{project_name}.zip"),
                               mime="application/zip")
            if errors:
                st.warning(f"Ø¨Ø¹Ø¶ Ø§Ù„Ù…Ù„ÙØ§Øª Ù„Ù… ØªÙØ­Ù…Ù‘Ù„ ({len(errors)}).")


if __name__ == "__main__":
    main()